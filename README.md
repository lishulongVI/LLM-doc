# 大模型时代

大模型：学习大规模文本语料库，获得强大的语言理解生成能力，能处理多样化任务。

基于大模型的api快速开发更强能力的应用，实现更新颖、实用的能力。



# 核心技术

1. 大模型部署调用
2. 提示工程技术
3. 函数调用：让大模型接入外部工具api，作为应用智能中枢
4. Embedding
5. 大模型微调



# 应用方向

1. 自然语言编程
2. 用户意图识别
3. 本地代码解释器
4. Agent开发
5. 私有知识库搭建
6. 模型端：大模型的下一个战场，All tools（LLM本身能力的增强->智能体） 、多模态，应用端：AGI时代（通用人工智能）





# 内容大纲



1. 如何训练垂直领域的大模型，大多数企业无力训练自己的大模型，统一的大模型产生，如何应用成为了主流
2. 如何构造提示词实现总结、推断、转换等多种常用功能
3. 如何基于chatgpt api构建对话系统
4. 如何基于langchain开发实用能力全面的应用
5. 如何使用langchain架构结合个人私有数据开发个性化应用
6. 如何赋予语言模型直接访问私有数据的能力，**提升回答质量**（大模型是基于训练数据集，不能有效利用私有数据）
7. 如何使用LangChain来整合自己的私有数据：加载切割本地文档、向量数据库&词向量、检索回答、基于私有数据的问答与聊天





# 一、提示工程

## 1、提示词设计技巧

### 1.1 预备知识

1. LLM交互输入：prompt

2. LLM交互输出：completion
3. 一个合理的prompt设计决定LLM能力的上限
4. 充分高效使用LLM，prompt技巧是重要的技能



### 1.2 LLM分类

1. 顶尖科技的底层技术垄断逐渐分化
   1. 开源大模型（技术&硬件门槛低）：Llama、Qwen、Baichuan、ChatGLM（zhipu ai）
   2. 在线大模型（数据安全）：ChatGpt、Gemini、GLM4
2. ChatGpt
   1. 基础LLM
   2. 指令微调LLM （instruction tuned）：通过专门的训练，更好的理解指令，更安全可靠的输出
      1. SFT："Supervised Fine-Tuning"，即监督微调
      2. RLHF： "Reinforcement Learning from Human Feedback"，即从人类反馈中进行强化学习



### 1.3 提示原则

1. LLM交互：编写清晰、具体的指令、给LLM思考时间，尽可能发挥LLM潜力

   1. 让LLM理解我们意图：清晰明确的表达需求，提供充足上下文
   2. 给LLM思考时间：指令加入逐步推理要求，给LLM充分思考时间，结果会准确可靠

2. 清晰、具体指令

   1. 避免提示词注入 prompt rejection：使用分隔符把不同的指令、上下文隔开，避免混淆
      1. `把用``` 括起来的文本总结成一句话`
   2. 结构化的输出：
      1. ```请生成xxx 并以Json格式提供，包含的key：x、y、z```
   3. 要求模型检查是否满足条件：边缘情况模型如何应对避免出现意外结果
      1. 如果不满足上面的主题，则直接写"未识别出主题"
   4. 提供少量示例：让LLM了解我们的要求和期望的输出格式

3. 给LLM思考时间：在prompt中加入逐步推理的要求

   1. 指定完成任务的步骤,

      ```
      执行以下操作：
      1- 对每条评论文本提取的关键信息进行一个简短概括，侧重在产品反馈上，下面用三个反引号括起来的是产品评论文本集合，每条评论通过｜分割
      2- 将每条评论简短概括翻译成英文
      3- 在英文里提取出在评论什么主题
      4- 输出评论主题列表
      
      请使用、分割您的答案
      
      reviews：
      ​```
      {review_prod}
      ​```
      ```

   2. LLM在下结论前找到自己的解法

      1. 指导LLM进行自主思考，获得更好效果
      2. 拆分任务、明确步骤

4. 局限性-> 可靠性&安全性

   1. 幻觉：会生成看似真实的编造知识
   2. 如何避免幻觉风险产生，通过prompt优化设计减少幻觉产生



## 2、迭代优化



### 2.1 迭代优化过程 -> 使用产品说明书生成营销话术

1. 生成文本长度限制，会总体接近预定长度 ：LLM在计算和判断文本长度的时依赖分词器
2. 处理文本细节：对不符合预期的completion，让LLM抓住重点，进行试错调整，逐步逼近最优
3. 添加表格描述



### 2.2 Tip

1. 掌握有效的prompt迭代开发和优化技巧
2. 需要多轮不断试错调整，不需要一开始就完美





## 3、基础NLP任务 -> 文本概括

> 高效精准获取信息

#### 3.1  单一文本概括

1. 限制输出文本长度
2. 关键角度侧重
   1. 侧重在产品反馈上
   2. 侧重在用户情绪上
3. 关键信息提取



#### 3.2 同时概括多条文本

1. 对于不同规模的评论文本，如何提升运算效率
2. 可以搭建主控面板来总结大量的用户评论，高效掌握客户的所有想法





## 4、基础NLP任务->推断



### 4.1 情感推断

1. 情感二分类：正面、反面
2. 识别情感类型：识别评论作者表达的情感，不超过五个，将答案格式化都好分割的单词列表
3. 识别愤怒：评论的作者是否表达了愤怒，给出是或否的答案



### 4.2 信息提取

1. 深入挖掘产品用户评论进行产品信息提取
2. 综合情感推断+信息提取
3. prompt： `如果信息不存在，请使用"未知"作为值`、`将是否愤怒值格式化为布尔值`、`评论文本中识别以下项目`



### 4.3 主题推断

1. 长文本，判断文本主旨，涉及哪些主题

2. prompt

   ```
   1. 确定一下给定文本中讨论的几个主题
   2. 每个主题使用1-4个词概括
   3. 请输出一个可解析的Python列表，每个元素是一个字符串展示一个主题
   
   ```



## 5、基础NLP任务->文本转换



#### 5.1 文本翻译

1. 多语言翻译、拼写纠正、语法调整、格式转换

2. 进行语气转换

3. 通用翻译器

4. prompt

   ```
   将以下中文翻译成英语，分别展示严肃跟淘气两种语气：
   
   请告诉我下面的文本是什么语种：
   
   请将以下文本分别翻译成中文、英文、法语和西班牙语：
   ```

   

#### 5.2 语气与写作风格调整

1. 语言语气跟受众对象相关，选择恰当的语言风格，内容更容易被受众群体接受理解



#### 5.3 文件格式转换

1. 更高效处理结构化数据
2. 将Json数据转换为html格式



#### 5.4 拼写&语法纠正

1. 自动校对

2. prompt

   ```
   请校对并更正一下文本，注意纠正文本保持原始语种，无需输出原始文本，如果没有发现任何错误，回答“为发现错误“
   ```



## 6、基础NLP任务->文本扩展

1. 润色，输入简短文本，生成丰富的长文
2. 辅助人类创作，可控制生成文本的随机性、多样性



